{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMSfeQylU3bxrT5co2CNyuF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gorantlasuhas/git_new/blob/main/dnnlab10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7m66mslk-Av",
        "outputId": "683ee6b9-a375-4366-bae1-6ad24e48c7ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1500/1500 [==============================] - 9s 5ms/step - loss: 0.4971 - accuracy: 0.8179 - val_loss: 0.3689 - val_accuracy: 0.8633\n",
            "Epoch 2/20\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3266 - accuracy: 0.8795 - val_loss: 0.3102 - val_accuracy: 0.8863\n",
            "Epoch 3/20\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.2842 - accuracy: 0.8942 - val_loss: 0.2880 - val_accuracy: 0.8927\n",
            "Epoch 4/20\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2557 - accuracy: 0.9056 - val_loss: 0.2749 - val_accuracy: 0.8950\n",
            "Epoch 5/20\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.2347 - accuracy: 0.9138 - val_loss: 0.2591 - val_accuracy: 0.9006\n",
            "Epoch 6/20\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.2153 - accuracy: 0.9202 - val_loss: 0.2651 - val_accuracy: 0.9053\n",
            "Epoch 7/20\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1970 - accuracy: 0.9266 - val_loss: 0.2722 - val_accuracy: 0.9018\n",
            "Epoch 8/20\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1825 - accuracy: 0.9310 - val_loss: 0.2764 - val_accuracy: 0.9026\n",
            "Epoch 9/20\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1677 - accuracy: 0.9371 - val_loss: 0.2810 - val_accuracy: 0.9041\n",
            "Epoch 10/20\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1555 - accuracy: 0.9413 - val_loss: 0.2818 - val_accuracy: 0.9022\n",
            "Epoch 11/20\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1410 - accuracy: 0.9469 - val_loss: 0.2934 - val_accuracy: 0.9038\n",
            "Epoch 12/20\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1300 - accuracy: 0.9506 - val_loss: 0.2953 - val_accuracy: 0.9046\n",
            "Epoch 13/20\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1184 - accuracy: 0.9551 - val_loss: 0.3334 - val_accuracy: 0.9035\n",
            "Epoch 14/20\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1112 - accuracy: 0.9583 - val_loss: 0.3410 - val_accuracy: 0.9048\n",
            "Epoch 15/20\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0985 - accuracy: 0.9628 - val_loss: 0.3545 - val_accuracy: 0.9043\n",
            "Epoch 16/20\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0917 - accuracy: 0.9662 - val_loss: 0.3475 - val_accuracy: 0.9010\n",
            "Epoch 17/20\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0862 - accuracy: 0.9676 - val_loss: 0.3821 - val_accuracy: 0.9032\n",
            "Epoch 18/20\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0815 - accuracy: 0.9693 - val_loss: 0.3739 - val_accuracy: 0.9037\n",
            "Epoch 19/20\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0715 - accuracy: 0.9730 - val_loss: 0.4211 - val_accuracy: 0.9044\n",
            "Epoch 20/20\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0687 - accuracy: 0.9740 - val_loss: 0.4309 - val_accuracy: 0.9022\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4904 - accuracy: 0.8998\n",
            "Test accuracy: 89.98000025749207\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize and reshape the data\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# Define the LeNet-5 model\n",
        "model = keras.Sequential()\n",
        "\n",
        "# First Convolutional Layer\n",
        "model.add(layers.Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1), padding='same'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "# Second Convolutional Layer\n",
        "model.add(layers.Conv2D(16, kernel_size=(5, 5), activation='relu', padding='same'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "# Flatten the output to feed into fully connected layers\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# First Fully Connected Layer\n",
        "model.add(layers.Dense(120, activation='relu'))\n",
        "\n",
        "# Second Fully Connected Layer\n",
        "model.add(layers.Dense(84, activation='relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Expand the dimensions of the data to match the LeNet-5 input shape\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(\"Test accuracy:\", test_acc * 100)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize and reshape the data\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# One-hot encode the target labels\n",
        "num_classes = 10\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "# Define the LeNet-5 model\n",
        "model = keras.Sequential()\n",
        "\n",
        "# First Convolutional Layer\n",
        "model.add(layers.Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1), padding='same'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "# Second Convolutional Layer\n",
        "model.add(layers.Conv2D(16, kernel_size=(5, 5), activation='relu', padding='same'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "# Flatten the output to feed into fully connected layers\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# First Fully Connected Layer\n",
        "model.add(layers.Dense(120, activation='relu'))\n",
        "\n",
        "# Second Fully Connected Layer\n",
        "model.add(layers.Dense(84, activation='relu'))\n",
        "\n",
        "# Output Layer\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model with categorical cross-entropy loss\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Expand the dimensions of the data to match the LeNet-5 input shape\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=30, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(\"Test accuracy:\", test_acc * 100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSk34zGG05BI",
        "outputId": "ffe47ad6-8f2d-48b7-aca4-129304deb76f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1500/1500 [==============================] - 9s 5ms/step - loss: 0.5197 - accuracy: 0.8103 - val_loss: 0.3743 - val_accuracy: 0.8658\n",
            "Epoch 2/30\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3459 - accuracy: 0.8742 - val_loss: 0.3394 - val_accuracy: 0.8777\n",
            "Epoch 3/30\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2970 - accuracy: 0.8902 - val_loss: 0.3014 - val_accuracy: 0.8907\n",
            "Epoch 4/30\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2676 - accuracy: 0.9020 - val_loss: 0.2748 - val_accuracy: 0.8996\n",
            "Epoch 5/30\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2449 - accuracy: 0.9086 - val_loss: 0.2771 - val_accuracy: 0.8995\n",
            "Epoch 6/30\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2245 - accuracy: 0.9160 - val_loss: 0.2660 - val_accuracy: 0.9070\n",
            "Epoch 7/30\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2093 - accuracy: 0.9209 - val_loss: 0.2673 - val_accuracy: 0.9053\n",
            "Epoch 8/30\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1948 - accuracy: 0.9269 - val_loss: 0.2657 - val_accuracy: 0.9061\n",
            "Epoch 9/30\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1774 - accuracy: 0.9332 - val_loss: 0.2750 - val_accuracy: 0.9032\n",
            "Epoch 10/30\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1647 - accuracy: 0.9380 - val_loss: 0.2637 - val_accuracy: 0.9103\n",
            "Epoch 11/30\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1532 - accuracy: 0.9430 - val_loss: 0.2780 - val_accuracy: 0.9072\n",
            "Epoch 12/30\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1397 - accuracy: 0.9474 - val_loss: 0.2847 - val_accuracy: 0.9039\n",
            "Epoch 13/30\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1309 - accuracy: 0.9494 - val_loss: 0.3024 - val_accuracy: 0.9029\n",
            "Epoch 14/30\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1209 - accuracy: 0.9534 - val_loss: 0.3103 - val_accuracy: 0.9076\n",
            "Epoch 15/30\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1102 - accuracy: 0.9591 - val_loss: 0.3204 - val_accuracy: 0.9026\n",
            "Epoch 16/30\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1040 - accuracy: 0.9602 - val_loss: 0.3481 - val_accuracy: 0.9043\n",
            "Epoch 17/30\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0962 - accuracy: 0.9631 - val_loss: 0.3453 - val_accuracy: 0.9023\n",
            "Epoch 18/30\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0905 - accuracy: 0.9648 - val_loss: 0.3959 - val_accuracy: 0.8997\n",
            "Epoch 19/30\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0847 - accuracy: 0.9679 - val_loss: 0.3967 - val_accuracy: 0.9003\n",
            "Epoch 20/30\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0771 - accuracy: 0.9703 - val_loss: 0.4179 - val_accuracy: 0.9006\n",
            "Epoch 21/30\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0716 - accuracy: 0.9726 - val_loss: 0.4356 - val_accuracy: 0.9005\n",
            "Epoch 22/30\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0663 - accuracy: 0.9746 - val_loss: 0.4344 - val_accuracy: 0.9013\n",
            "Epoch 23/30\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0690 - accuracy: 0.9738 - val_loss: 0.4754 - val_accuracy: 0.8953\n",
            "Epoch 24/30\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0615 - accuracy: 0.9764 - val_loss: 0.4717 - val_accuracy: 0.9010\n",
            "Epoch 25/30\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0599 - accuracy: 0.9772 - val_loss: 0.5177 - val_accuracy: 0.8990\n",
            "Epoch 26/30\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0545 - accuracy: 0.9793 - val_loss: 0.5327 - val_accuracy: 0.8984\n",
            "Epoch 27/30\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0528 - accuracy: 0.9802 - val_loss: 0.5492 - val_accuracy: 0.8992\n",
            "Epoch 28/30\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0522 - accuracy: 0.9800 - val_loss: 0.5086 - val_accuracy: 0.9012\n",
            "Epoch 29/30\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0467 - accuracy: 0.9826 - val_loss: 0.5699 - val_accuracy: 0.9024\n",
            "Epoch 30/30\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0449 - accuracy: 0.9833 - val_loss: 0.5940 - val_accuracy: 0.9005\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.6350 - accuracy: 0.9005\n",
            "Test accuracy: 90.04999995231628\n"
          ]
        }
      ]
    }
  ]
}